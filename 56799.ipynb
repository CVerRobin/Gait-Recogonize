{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data4444\r\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!ls /home/aistudio/data/\n",
    "# !unzip /home/aistudio/data/data4444/GaitDatasetA-silh.zip -d /home/aistudio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看个人持久化工作区文件\n",
    "!ls /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于GEI的HOG特征，使用SVM分类器分类步态识别\r\n",
    "\r\n",
    "采用中科院自动化所GaitDatasetA-silh小型步态识别数据集进行实验分析\r\n",
    "\r\n",
    "将数据集每人序列帧图像平均分为两部分，一部分为训练集，一部分为测试集\r\n",
    "\r\n",
    "对行人二值化序列帧图像求平均得到GEI步态能量图，再采用OpenCV内置HOGDescriptor提取出GEI的HOG特征值，利用HOG特征训练SVM分类器，最终采用模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "\r\n",
    "def cut_img(img, T_H, T_W):\r\n",
    "    # 获得最高点和最低点\r\n",
    "    y = img.sum(axis=1)\r\n",
    "    y_top = (y != 0).argmax(axis=0)\r\n",
    "    y_btm = (y != 0).cumsum(axis=0).argmax(axis=0)\r\n",
    "    img = img[y_top:y_btm + 1, :]\r\n",
    "    # 如果高比宽要大，用高计算 resize 的比例\r\n",
    "    _r = img.shape[1] / img.shape[0]\r\n",
    "    _t_w = int(T_H * _r)\r\n",
    "    img = cv.resize(img, (_t_w, T_H), interpolation=cv.INTER_CUBIC)\r\n",
    "    # 获得人的对称轴\r\n",
    "    sum_point = img.sum()\r\n",
    "    sum_column = img.sum(axis=0).cumsum()\r\n",
    "    x_center = -1\r\n",
    "    for i in range(sum_column.size):\r\n",
    "        if sum_column[i] > sum_point / 2:\r\n",
    "            x_center = i\r\n",
    "            break\r\n",
    "    h_T_W = int(T_W / 2)\r\n",
    "    left = x_center - h_T_W\r\n",
    "    right = x_center + h_T_W\r\n",
    "    if left <= 0 or right >= img.shape[1]:\r\n",
    "        left += h_T_W\r\n",
    "        right += h_T_W\r\n",
    "        _ = np.zeros((img.shape[0], h_T_W))\r\n",
    "        img = np.concatenate([_, img, _], axis=1)\r\n",
    "    img = img[:, left:right]\r\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片预处理\r\n",
    "对人体区域进行裁剪，将人体对称轴放于图片中央。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEI步态能量图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_GEI(imgs):\r\n",
    "    GEI = (imgs[0]/255).astype(\"uint8\")\r\n",
    "    for img in imgs[1:]:\r\n",
    "        GEI += (img/255).astype(\"uint8\")\r\n",
    "    GEI = GEI/len(imgs)\r\n",
    "\r\n",
    "    return (GEI*255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取HOG特征\r\n",
    "采用opencv封装的HOGDescriptor进行HOG特征计算\r\n",
    "\r\n",
    "block大小为8 * 8\r\n",
    "cell大小为8 * 8\r\n",
    "每个block 取 9 个 bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SZ=20\r\n",
    "bin_n = 16 # Number of bins\r\n",
    "affine_flags = cv.WARP_INVERSE_MAP|cv.INTER_LINEAR\r\n",
    "def get_Hog(img):\r\n",
    "    winSize = (img.shape[1], img.shape[0])      # winSize = (64,64)\r\n",
    "    blockSize = (8,8)                               # blockSize = (16,16)\r\n",
    "    blockStride = (8,8)\r\n",
    "    cellSize = (8,8)\r\n",
    "    nbins = 9\r\n",
    "    derivAperture = 1\r\n",
    "    winSigma = 4.\r\n",
    "    histogramNormType = 0\r\n",
    "    L2HysThreshold = 2.0000000000000001e-01\r\n",
    "    gammaCorrection = 0\r\n",
    "    nlevels = 64\r\n",
    "    hog = cv.HOGDescriptor(winSize,blockSize,blockStride,\r\n",
    "                  cellSize,nbins,derivAperture,\r\n",
    "                  winSigma,histogramNormType,L2HysThreshold,\r\n",
    "                  gammaCorrection,nlevels)\r\n",
    "    #compute(img[, winStride[, padding[, locations]]]) -> descriptors\r\n",
    "    winStride = (8,8)\r\n",
    "    padding = (8,8)\r\n",
    "    locations = [] # (10, 10)# ((10,20),)\r\n",
    "    hist = hog.compute(img,winStride,padding,locations)\r\n",
    "    # hist.dtype = np.float64\r\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取GaitDatasetA-silh数据集文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fyc', 'xxj', 'ml', 'zdx', 'lsl', 'wl', 'zyf', 'rj', 'wq', 'lqf', 'zc', 'ljg', 'zjg', 'yjf', 'xch', 'zl', 'syj', 'hy', 'nhz', 'wyc']\n",
      "['fyc_00_3', 'fyc_90_4', 'fyc_00_2', 'fyc_90_3', 'fyc_45_1', 'fyc_45_4', 'fyc_00_4', 'fyc_00_1', 'fyc_45_3', 'fyc_90_2', 'fyc_45_2', 'fyc_90_1', 'xxj_00_3', 'xxj_90_4', 'xxj_00_2', 'xxj_90_3', 'xxj_45_1', 'xxj_45_4', 'xxj_00_4', 'xxj_00_1', 'xxj_45_3', 'xxj_90_2', 'xxj_45_2', 'xxj_90_1', 'ml_00_3', 'ml_90_4', 'ml_00_2', 'ml_90_3', 'ml_45_1', 'ml_45_4', 'ml_00_4', 'ml_00_1', 'ml_45_3', 'ml_90_2', 'ml_45_2', 'ml_90_1', 'zdx_00_3', 'zdx_90_4', 'zdx_00_2', 'zdx_90_3', 'zdx_45_1', 'zdx_45_4', 'zdx_00_4', 'zdx_00_1', 'zdx_45_3', 'zdx_90_2', 'zdx_45_2', 'zdx_90_1', 'lsl_00_3', 'lsl_90_4', 'lsl_00_2', 'lsl_90_3', 'lsl_45_1', 'lsl_45_4', 'lsl_00_4', 'lsl_00_1', 'lsl_45_3', 'lsl_90_2', 'lsl_45_2', 'lsl_90_1', 'wl_00_3', 'wl_90_4', 'wl_00_2', 'wl_90_3', 'wl_45_1', 'wl_45_4', 'wl_00_4', 'wl_00_1', 'wl_45_3', 'wl_90_2', 'wl_45_2', 'wl_90_1', 'zyf_00_3', 'zyf_90_4', 'zyf_00_2', 'zyf_90_3', 'zyf_45_1', 'zyf_45_4', 'zyf_00_4', 'zyf_00_1', 'zyf_45_3', 'zyf_90_2', 'zyf_45_2', 'zyf_90_1', 'rj_00_3', 'rj_90_4', 'rj_00_2', 'rj_90_3', 'rj_45_1', 'rj_45_4', 'rj_00_4', 'rj_00_1', 'rj_45_3', 'rj_90_2', 'rj_45_2', 'rj_90_1', 'wq_00_3', 'wq_90_4', 'wq_00_2', 'wq_90_3', 'wq_45_1', 'wq_45_4', 'wq_00_4', 'wq_00_1', 'wq_45_3', 'wq_90_2', 'wq_45_2', 'wq_90_1', 'lqf_00_3', 'lqf_90_4', 'lqf_00_2', 'lqf_90_3', 'lqf_45_1', 'lqf_45_4', 'lqf_00_4', 'lqf_00_1', 'lqf_45_3', 'lqf_90_2', 'lqf_45_2', 'lqf_90_1', 'zc_00_3', 'zc_90_4', 'zc_00_2', 'zc_90_3', 'zc_45_1', 'zc_45_4', 'zc_00_4', 'zc_00_1', 'zc_45_3', 'zc_90_2', 'zc_45_2', 'zc_90_1', 'ljg_00_3', 'ljg_90_4', 'ljg_00_2', 'ljg_90_3', 'ljg_45_1', 'ljg_45_4', 'ljg_00_4', 'ljg_00_1', 'ljg_45_3', 'ljg_90_2', 'ljg_45_2', 'ljg_90_1', 'zjg_00_3', 'zjg_90_4', 'zjg_00_2', 'zjg_90_3', 'zjg_45_1', 'zjg_45_4', 'zjg_00_4', 'zjg_00_1', 'zjg_45_3', 'zjg_90_2', 'zjg_45_2', 'zjg_90_1', 'yjf_00_3', 'yjf_90_4', 'yjf_00_2', 'yjf_90_3', 'yjf_45_1', 'yjf_45_4', 'yjf_00_4', 'yjf_00_1', 'yjf_45_3', 'yjf_90_2', 'yjf_45_2', 'yjf_90_1', 'xch_00_3', 'xch_90_4', 'xch_00_2', 'xch_90_3', 'xch_45_1', 'xch_45_4', 'xch_00_4', 'xch_00_1', 'xch_45_3', 'xch_90_2', 'xch_45_2', 'xch_90_1', 'zl_00_3', 'zl_90_4', 'zl_00_2', 'zl_90_3', 'zl_45_1', 'zl_45_4', 'zl_00_4', 'zl_00_1', 'zl_45_3', 'zl_90_2', 'zl_45_2', 'zl_90_1', 'syj_00_3', 'syj_90_4', 'syj_00_2', 'syj_90_3', 'syj_45_1', 'syj_45_4', 'syj_00_4', 'syj_00_1', 'syj_45_3', 'syj_90_2', 'syj_45_2', 'syj_90_1', 'hy_00_3', 'hy_90_4', 'hy_00_2', 'hy_90_3', 'hy_45_1', 'hy_45_4', 'hy_00_4', 'hy_00_1', 'hy_45_3', 'hy_90_2', 'hy_45_2', 'hy_90_1', 'nhz_00_3', 'nhz_90_4', 'nhz_00_2', 'nhz_90_3', 'nhz_45_1', 'nhz_45_4', 'nhz_00_4', 'nhz_00_1', 'nhz_45_3', 'nhz_90_2', 'nhz_45_2', 'nhz_90_1', 'wyc_00_3', 'wyc_90_4', 'wyc_00_2', 'wyc_90_3', 'wyc_45_1', 'wyc_45_4', 'wyc_00_4', 'wyc_00_1', 'wyc_45_3', 'wyc_90_2', 'wyc_45_2', 'wyc_90_1']\n"
     ]
    }
   ],
   "source": [
    "roots = \"/home/aistudio/GaitDatasetA-silh/\"\r\n",
    "cells = []\r\n",
    "labels = []\r\n",
    "label = os.listdir(roots)\r\n",
    "print(label)\r\n",
    "# print(label)\r\n",
    "for dir_ in label:\r\n",
    "    dirs = os.listdir(roots + dir_)\r\n",
    "    for dir__ in dirs:\r\n",
    "        # print(dir_ + \"_\" + dir__)\r\n",
    "        for root_,dirs_,files in os.walk(roots + dir_ + \"/\" + dir__):\r\n",
    "            # print(root_)\r\n",
    "            imgs = []\r\n",
    "            for file in files:\r\n",
    "                srcImg = cv.imread(root_ + \"/\" + file,0)\r\n",
    "                imgs.append(cut_img(srcImg,128,128))\r\n",
    "            cells.append(imgs)\r\n",
    "        labels.append(dir_ + \"_\" + dir__)\r\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据分为训练集与测试集两部分\r\n",
    "训练集每人每方向图片数目从1到26各一组\r\n",
    "\r\n",
    "测试集为每人数据的后8张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "minlength = len(cells[0])//2\r\n",
    "for cell in cells:\r\n",
    "    if minlength > len(cell)//2:\r\n",
    "        minlength = len(cell)//2\r\n",
    "    else:\r\n",
    "        continue\r\n",
    "        \r\n",
    "\r\n",
    "train_cells = []\r\n",
    "for cell in cells:\r\n",
    "    train_cells.append(cell[:len(cell)//2])\r\n",
    "    \r\n",
    "test = []\r\n",
    "for i in range(1,minlength):\r\n",
    "    test_cells = []\r\n",
    "    for cell in cells:\r\n",
    "        test_cells.append(cell[-minlength+i:])\r\n",
    "    test.append(test_cells)\r\n",
    "print(len(train_cells))\r\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对训练集构建基于GEI的HOG特征\r\n",
    "将训练集数据读入，首先提取GEI步态能量图\r\n",
    "\r\n",
    "然后对GEI提取HOG特征，每张GEI的HOG特征为20736 * 1大小\r\n",
    "\r\n",
    "标记240个训练数据，按照人进行编号，每个人12组数据，共20人\r\n",
    "\r\n",
    "输出折线图横轴为HOG数据编号，共240个；纵轴为对应人员编号，共20个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 20736, 1)\n"
     ]
    }
   ],
   "source": [
    "responses = []\r\n",
    "\r\n",
    "traingeis = []\r\n",
    "for train_cell in train_cells:\r\n",
    "    traingeis.append(get_GEI(train_cell))\r\n",
    "\r\n",
    "trainhogs = []\r\n",
    "for traingei in traingeis:\r\n",
    "    trainhog = get_Hog(traingei)\r\n",
    "    trainhogs.append(trainhog)\r\n",
    "trainData = np.float32(trainhogs).reshape(-1,20736,1)\r\n",
    "responses = np.repeat(np.arange(20),12)[:,np.newaxis]\r\n",
    "print(trainData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对测试集构建基于GEI的HOG特征\r\n",
    "\r\n",
    "与训练集处理方式相同，每个HOG特征为20736 * 1大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "def maketestData(test_cells):\r\n",
    "    testgeis = []\r\n",
    "    for test_cell in test_cells:\r\n",
    "        testgeis.append(get_GEI(test_cell))\r\n",
    "    testhogs = []\r\n",
    "    for testgei in testgeis:\r\n",
    "        testhog = get_Hog(testgei)\r\n",
    "        testhogs.append(testhog)\r\n",
    "    testData = np.float32(testhogs).reshape(-1,20736,1)\r\n",
    "    return testData\r\n",
    "\r\n",
    "testDatas = []\r\n",
    "for test_cells in test:\r\n",
    "    testDatas.append(maketestData(test_cells))\r\n",
    "print(len(testDatas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采用线性内核函数训练OpenCV内置SVM分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm = cv.ml.SVM_create()\r\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\r\n",
    "svm.setType(cv.ml.SVM_C_SVC)\r\n",
    "svm.setC(8.35)\r\n",
    "svm.setGamma(3.58)\r\n",
    "svm.train(trainData,cv.ml.ROW_SAMPLE,responses)\r\n",
    "svm.save('svm_data.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用训练好的模型进行预测\r\n",
    "分析测试集大小对模型预测准确度的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.916666666666668\n",
      "25.416666666666668\n",
      "35.833333333333336\n",
      "49.166666666666664\n",
      "57.5\n",
      "66.66666666666667\n",
      "70.41666666666667\n",
      "74.16666666666667\n",
      "79.16666666666667\n",
      "84.58333333333333\n",
      "88.33333333333333\n",
      "90.41666666666667\n",
      "91.25\n",
      "92.5\n",
      "93.75\n",
      "96.25\n"
     ]
    }
   ],
   "source": [
    "results = []\r\n",
    "corrects = []\r\n",
    "def svmpredict(i):\r\n",
    "    result = svm.predict(testDatas[len(testDatas)-i-1])[1].astype(\"int\")\r\n",
    "    mask = result==responses\r\n",
    "    correct = np.count_nonzero(mask)\r\n",
    "    print(correct*100.0/result.size)\r\n",
    "    results.append(result)\r\n",
    "    corrects.append(correct*100.0/result.size)\r\n",
    "    \r\n",
    "for i in range(len(test)):\r\n",
    "    svmpredict(i)\r\n",
    "plt.title(\"Predict correct rate\")\r\n",
    "plt.xlabel(\"Number of images choosen to test model\")\r\n",
    "plt.ylabel(\"Correct rate\")\r\n",
    "plt.plot(corrects)\r\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.3.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
